---
title: "Pierwszy raport z symulacji Monte Carlo"
author: "Jan Kozłowski"
date: "19-12-2024"
output: 
  pdf_document:
    extra_dependencies: ["amsmath","dsfont","xcolor"]
    fig_caption: yes
header-includes:
- \usepackage{booktabs}
- \usepackage{dsfont}
- \usepackage{float}
urlcolor: blue

---


```{r setup, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
setwd("C:/Users/jaako/Desktop/studia/Monte Carlo/MC_sim_proj1")
library(ggplot2)
library(kableExtra)

second_level_p_value<-function(p_val){
  n<-length(p_val)
  parts<-seq(0,1,0.1)
  R<-replicate(10,0.1*n)
  ilosc_w_przedzialach<-sapply(1:10, function(i){
    sum(p_val>=parts[i]&p_val<parts[i+1])
  })
  1-pchisq(sum((ilosc_w_przedzialach-R)^2/R),9)
}



dane<-read.csv('wyniki_zad1.csv',header = T)

dane$P.value<-as.numeric(dane$P.value)
dane$n<-as.numeric(dane$n)


```

```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
narysuj_zad_2<-function(dane2,l){
  dane2$P.value <-as.numeric(dane2$P.value)
  dane2$n <-as.numeric(dane2$n)
  n <-dane2$n[1]
  
  p<-ggplot(dane2,aes(x   = P.value,fill = Liczba,col = Liczba))+
    geom_histogram(position = "identity",binwidth = 0.02)+facet_wrap(~Liczba)+
    theme(legend.position = "bottom",plot.title = element_text(hjust = 0.5),
          plot.subtitle = element_text(hjust = 0.5))+ 
    labs(title = "Histogtamy p_wartosci dla różnych liczb",
         subtitle = paste("dla n =",n),
         x="P_wartość",y="")+
           labs(caption = paste("Wykres ",l))
  
  p_val<-data.frame(matrix(ncol = 3,nrow = 1))
  colnames(p_val)<-c("Pi","e","sqrt2")
  p_val[1]<-second_level_p_value(subset(dane2,dane2$Liczba =="Pi")$P.value)
  p_val[2]<-second_level_p_value(subset(dane2,dane2$Liczba =="e")$P.value)
  p_val[3]<-second_level_p_value(subset(dane2,dane2$Liczba =="sqrt2")$P.value)
  print(p)
  
  return(p_val)
}
```


```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}


p_values_second<-data.frame(matrix(ncol = 4, nrow = 4))

p_values_second[1,1]<-second_level_p_value(subset(dane,dane$Test=="KS"&
                                                    dane$Generator=="GLCG")$P.value)
p_values_second[2,1]<-second_level_p_value(subset(dane,dane$Test=="Chi"&
                                                    dane$Generator=="GLCG")$P.value)
p_values_second[3,1]<-second_level_p_value(subset(dane,dane$Test=="poker"&
                                                    dane$Generator=="GLCG")$P.value)
p_values_second[4,1]<-second_level_p_value(subset(dane,dane$Test=="Furier"&
                                                    dane$Generator=="GLCG")$P.value)

p_values_second[1,2]<-second_level_p_value(subset(dane,dane$Test=="KS"&
                                                    dane$Generator=="RC")$P.value)
p_values_second[2,2]<-second_level_p_value(subset(dane,dane$Test=="Chi"&
                                                    dane$Generator=="RC")$P.value)
p_values_second[3,2]<-second_level_p_value(subset(dane,dane$Test=="poker"&
                                                    dane$Generator=="RC")$P.value)
p_values_second[4,2]<-second_level_p_value(subset(dane,dane$Test=="Furier"&
                                                    dane$Generator=="RC")$P.value)

p_values_second[1,3]<-second_level_p_value(subset(dane,dane$Test=="KS"&
                                                    dane$Generator=="Marsagli")$P.value)
p_values_second[2,3]<-second_level_p_value(subset(dane,dane$Test=="Chi"&
                                                    dane$Generator=="Marsagli")$P.value)
p_values_second[3,3]<-second_level_p_value(subset(dane,dane$Test=="poker"&
                                                    dane$Generator=="Marsagli")$P.value)
p_values_second[4,3]<-second_level_p_value(subset(dane,dane$Test=="Furier"&
                                                    dane$Generator=="Marsagli")$P.value)

p_values_second[1,4]<-second_level_p_value(subset(dane,dane$Test=="KS"&
                                                    dane$Generator=="Ziff")$P.value)
p_values_second[2,4]<-second_level_p_value(subset(dane,dane$Test=="Chi"&
                                                    dane$Generator=="Ziff")$P.value)
p_values_second[3,4]<-second_level_p_value(subset(dane,dane$Test=="poker"&
                                                    dane$Generator=="Ziff")$P.value)
p_values_second[4,4]<-second_level_p_value(subset(dane,dane$Test=="Furier"&
                                                    dane$Generator=="Ziff")$P.value)


colnames(p_values_second)<-c("GLCG","RC(32)","Marsagli","Ziff")
rownames(p_values_second)<-c("KS","Chi","Poker","Fourier")

```


\begin{center}
 \textbf{Wprowadzenie}
\end{center}
Celem tego projektu jest opisanie i zbadanie różnych generatorów liczb pseudolosowych, oraz testów, które będą sprawdzać "jakość" tych generatorów. Raport zaczniemy od napisiania algorytmów 4 generatorów, $\text{GLCG}$, $\text{RC4}$, $\text{Marsa-LFIB4}$ oraz $\text{Ziff98}$, następnie opisanie 4 testów: Kołmogorowa-Smirnowa, $\chi^2$, testu pokerowego i dyskretnego testu transformaty Fouriera(Discrete Fourier Transform (Spectral) Test)

\begin{center}
 \textbf{Generator Fibonacciego}
\end{center}

Patrząc na wzór rekurencyjny generatora $\text{GLCG}$ możemy zauważyć, że jego wadą będzie duża korelacja pomiędzy kolejnymi zmiennymi. Jendym z możliwości poprawy tej własności jest zwiększenie rekurencji tzn. zamiast olbiczać $n$-ty wyraz za pomocią wyrazów $n-1,n-2,\dots,n-i$ będziemy używać wyrazów $n-q_1,n-q_2,\dots,n-q_i$, gdzie liczby $q_j$ są "duże". Dodatkowo, jako że ostatnim dziłaniem rekurencji jest wzięcie reszty dzielenia przez $M$, to działanie, jakie wykonujemy pomiędzy $x_j$ nie musi być dodawanie, więc nasza rekurencja będzie miałą wtedy postać:

$$x_n = x_{n-q_1}\diamond x_{n-q_2}\diamond \dots x_{n-q_k} \quad modM,$$
gdzie $\diamond$ jest pewnym działaniem w liczbach całkowitych.
Stąd dostajemy dwa możliwe generatory:\newline
-generator Marsagli:$k = 4$, $p_1 = 55,p_2 = 119,p_3 = 179,p_4 = 256,M = 2^{10},\diamond = +$, \newline
-generator Ziffa:$k = 4$, $p_1 = 471,p_2 = 1586,p_3 = 6988,p_4 = 9689,M = 2^{10},\diamond = xor$,\newline

gdzie operator $xor$ dla dwóch liczb to zamienienie ich na postać binarną i nałożenie $xor$ na każdą parę bitów.
 
W przykładach będziemy używać dla generatora $GLCG$ parametrów $M = 2^{10}$, $k = 3$, $\{a_i\}_{i=1}^k = (3,7,68)$ oraz $\{x_i\}_{i=1}^k = (1,2,5)$,

Dla generatora $RC(32)$ będziemy używać parametrów $M = 2^5$,$K = (2,3,4,7)$,

Generatory Ziffa i Marsagli wymagają długiej listy parametrów $x_1,\dots,x_{q_{k}}$, więc do jej stworzenia użyjemy generatora $GLCG$.


\begin{center}
 \textbf{Test pokerowy}
\end{center}

W tym teście będziemy dzielić nasz ciąg liczb $X_1,\dots,X_{5n}$ na podciągi długości 5 i badać ile jest w danym podciągu różnych liczb. Zapiszmy to jako $Y_1,\dots, Y_n$, teraz będziemy chcieli na tym wektorze przeprowadzić test $\chi^2$, więc jedynym, co nam zostaje do policzenia są prawdopodobieństwa $p_s = P[Y_i = s]$. 
Prawdopodobieństwo, że losując pięciokrotnie ze zbioru od 1 do $M$ otrzymamy dokładnie $s$ różnych liczb wynosi 
$$\frac{M(M-1)\dots(M-s+1)}{M^5}S_2(5,s)$$
gdzie $S_2(5,s)$ oznacza liczbę podziału zbioru 5-elementowego na $s$ niepustych podzbiorów. Można policzyć, że 
$S_2(5, 1) = 1, S_2(5, 2) = 15, S_2(5, 3) = 25, S_2(5, 4) = 10, S_2(5, 5) = 1$.
Mając to, możemy policzyć 
$$O_s = \#\{i:Y_i = s\}.$$
Wtedy statystyka 
$$\hat{\chi}^2 = \sum_{i=1}^5\frac{(O_i-np_i)^2}{np_i},$$
ma rozkład $\chi^2$ z 4 stopniami swobody. 
\begin{center}
 \textbf{Dyskretny test transformaty Fouriera}
\end{center}

Ten test opiera się na dyskretniej transformacie Fouriera, która zamienia ciąg $x_1,\dots,x_n$ w ciąg $a_1,\dots,a_n$ w sposób:
$$a_k = \sum_{i=1}^nx_iw_n^{-(n-1)k},$$
gdzie $w_n = e^{i\frac{2\pi}{n}}$

Test ten bierze ciąg bitów, więc w naszym przykładie będziemy musieli zamienić nasz ciąg w takowy: mając ciąg liczb z przedziału $[0,1]$ zamieńmy liczby mniejsze od 0.5 w 0, a większe lub równe w 1. Nazwijmy ten ciąg bitów $X_1,\dots, X_n$. Teraz zamieńmy go w ciąg $Y_i = 2X_i-1$ i na ciąg $Y_1,\dots,Y_n$ zaaplikujmy dyskretną transformacię Fouriera otzrybując ciąg $S_1,\dots, S_n$. Teraz niech dla $i = 1,\dots, \frac{n}{2}$ mamy $M_i = |S_i|$. Można pokazać, że przy $H_0$ 95% wartości $M_i$ powinno być mniejsze od $T = \sqrt{\ln(\frac{1}{0.05})n}$.
Niech $N_0 = 0.95\frac{n}{2}$, oczekiwana ilość wartości mniejszych niż $T$, a niech $N_1 = \#\{i:M_i<T\}$ to obserwowana ilośc. Licząc 
$$d = \frac{N_1-N_0}{\sqrt{\frac{n*0.95*0.05}{4}}},$$
możemy policzyć p_wartość ze wzoru $p_v = erfc(\frac{|d|}{\sqrt{2}})$
\begin{center}
 \textbf{Second level testing}
\end{center}

Wyobraźmy sobie sytuację, że mamy generator, który za każdym razem zwraca przy testowaniu jego działania tę samą p-wartość, która jest większa niż poziom istotności, wtedy ten generator nie jest dobry, ponieważ generowanie przez niego bity(czyli też p-wartości) powinny być niezależne. Pamiętając o tym spostrzeżeniu, jak i o fakcie, że gdy $H_0$ jest prawdziwe, to rozkład p-wartości jest jednostwajny na $[0,1]$ możemy stworzyć nowy test nazwany second level testing: podzielny nasz ciąg bitów do testowania na $R$ mniejszych podciągów i każdy z nich przetestujmy otrzymując ciąg p_wattości, na których możemy przeprowadzić test $\chi^2$

\begin{center} 
 \textbf{Zadanie 1}
\end{center}

Teraz zobatrzmy jakie wyniki będą dawać nasze generatory dla różnych testów. Będziemy generować $k = 1000$ p-wartości, każda policzona z ciągu długości $n=1000$:
 
```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
ggplot(dane,aes(x = P.value,fill = Test,col = Test))+
  geom_histogram(position = "identity",alpha = 0.5)+facet_wrap(~Generator)+
  theme(legend.position = "bottom",plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5))+ 
  labs(title = "Histogtamy p_wartosci dla różnych testów",
       subtitle = "i różnych generatorów",
       x="P_wartość",y="")+
           labs(caption = "Wykres 1")
```

Możemy zauważyć, że p-wartości testu pokerowego dla każdego generatora są bardzo skrajne: albo prawie równe 0 albo 1. Wynikać to może z tego, że losujemy wśród bardzo wielu liczb, ponieważ $M$ jest duże, więc szansa, że w 5-ciu liczbach będą dwie takie same, jest bardzo mała, co przy takiej próbie może dawać duże odchylenia. Kolejną obserwacją jest to, że p_wartości testu Furiera są bardzo dyskretne, tzn skupione w kilku punktach, to może być spowodowane małą próbką. JEśli chcemy porówanać wyniki generatorów, to wydaje się, że oba generatory Fibonaciego dają najlepsze wyniki, ale policzmy jeste p-wartości dla second level testing:

```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
kable(p_values_second)
```

Z omówionych wyżej powodów testy pokerowy i Fouriera dają p-wartości praktycznie równe 0. A dla pozostałych testów najlepiej wypada generator Marsagli.

\begin{center}
 \textbf{Zadanie 2}
\end{center}
 
Teraz opiszmny inny sposób generowania liczb w sposób pseudolosowy: weźmy jakąś niewymierną liczbę rzeczywistą i rozpiszmy ją w nieskończonym rozwinięciu dwójkowym. Możemy podejrzewać, że taki ciąg będzie ciągiem niezależnych bitów. Sprawdzimy to na podstawie rozwinięć $\pi$,$e$ oraz $\sqrt{2}$ i testu monobit. Zaczniemy od wczytania pierwszego miliona cyfr każdej z tych liczb, następne te ciągi podzieliny na mniejsze ciągi długości $n = 1000$
z każdy taki ciąg bitów $B^i_1,\dots,B^i_n$ zamieńmy na liczbę 

$$S_i = \frac{1}{\sqrt{2}}\sum_{j=1}^nB_j^.$$
Z CTG ciąg $S_i$ dąży do $N(0,1)$, więc możemy policzyć p-warość:
$$p_i = 2(1-\phi(|S_i|)),$$
gdzie $\phi$ to dystrybuanta rozkładu normalnego standardowego.
Zobaczmy jak wyglądają histogramy tych p-wartości dla naszych liczb $\pi$,$e$ i $\sqrt{2}$:

 
```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
dane2<-read.csv('wyniki_zad2_n_1000.csv',header = T)
r1<-narysuj_zad_2(dane2,2)

```
 Widzimy, że liczby te mniej więcej rozkładają się jednostajnie na przedziale $[0,1]$, co mogłoby sugerować, że hipoteza o tym, że nasz początkowy ciąg bitów jest iid. jest prawdziwa, ale wykonajmy jeszcze second level testing i policzmy ich p-wartości:


```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
kable(r1)
```

Wszytkie one są tak małe, że komputer uważa je za równe zero, przyczyną tego może być za mała liczba $n$, która sprawia, że rozkład $S_i$ nie jest jeszcze "blisko" rozkładu normalnemu, dlatego ustawmy $n= 5000$ i powtóżmy nasze obliczenia:


 
```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
dane2<-read.csv('wyniki_zad2_n_5000.csv',header = T)
r2<-narysuj_zad_2(dane2,3)

```

Widzimy, że tym razem rozkład tych p-wartości jest bardziej równomiernie równomiernie rozłożony, zobatrzmy jak to wpływa na second level testing i jego p-wartość:


```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
kable(r2)
```

Tym razem w żadnym przypadku nie możemy odżucić $H_0$, lecz musimy pamiętać, że zwiększając $n$ mniejszamy ilość zmiennych $S_i$, co też wpływa na p_wartość. 

\begin{center}
 \textbf{Tabela wywoływania funkcji}
\end{center}

W tym projekcjie postanowiłem najpierw gererować liczby pseudolosowe i testować je "pierwszo poziomowo" w pythonie, później zapisywać wyniki w postaci .csv, a wykresy i second level testong przeprowadziać w R. Poniżej jest przedstwaiona tabela z nazwami funkcji, które zapisują dane to wykesu o danej nazwie.
 
```{r, include=TRUE ,warning=FALSE, message=FALSE, echo=FALSE}
do_zapisywania<-data.frame(matrix(ncol = 3,nrow = 3))
colnames(do_zapisywania)<-c("nazwa pliku","nazwa funkcji","parametry")
rownames(do_zapisywania)<-c("Wykres 1","Wykres 2","Wykres 3")
do_zapisywania[1,]<-c("wyniki_zad1.csv","policz_i_zapisz_wyniki_zad1","n=1000,k=1000")
do_zapisywania[2,]<-c("wyniki_zad2_n_1000.csv","read_numbers_and_save_p_values","n=1000")
do_zapisywania[3,]<-c("wyniki_zad2_n_5000.csv","read_numbers_and_save_p_values","n=5000")
kable(do_zapisywania)

```
